{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fa59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF AUC: 0.7857937071987869\n",
      "Best LR AUC: 0.7864147118742563\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best XGB AUC: 0.7845484489024894\n",
      "Best CatBoost AUC: 0.7910267422083067\n",
      "[LightGBM] [Info] Number of positive: 16241, number of negative: 16241\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13440\n",
      "[LightGBM] [Info] Number of data points in the train set: 32482, number of used features: 65\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best LightGBM AUC: 0.7864708617830417\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 150\u001b[0m\n\u001b[0;32m    143\u001b[0m best_lgb \u001b[38;5;241m=\u001b[39m grid_lgb\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# ===== VOTING CLASSIFIER =====\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# VotingClassifier butuh model tanpa pipeline, jadi kita buat pipeline yang hanya preprocessing dan smote, lalu classifier tanpa preprocessing di voting:\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Cara: Voting model dengan classifier yang sudah dilatih (tanpa preprocessing lagi), jadi kita akan lakukan prediksi di data yang sudah diproses.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Proses test data dengan preprocessor (tanpa SMOTE)\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m X_test_processed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Fit VotingClassifier on training data yang sudah diproses dan di-SMOTE\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Kita proses training data dengan preprocessor + smote sekali lagi agar voting bisa belajar.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Tapi VotingClassifier tidak support pipeline secara langsung dengan smote, jadi kita proses manual:\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# Preprocess dan SMOTE untuk training data\u001b[39;00m\n\u001b[0;32m    157\u001b[0m X_train_processed \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_train)\n",
      "File \u001b[1;32mc:\\Users\\axell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\axell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:973\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform X separately by each transformer, concatenate results.\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \n\u001b[0;32m    949\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;124;03m    sparse matrices.\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    972\u001b[0m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 973\u001b[0m \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    974\u001b[0m X \u001b[38;5;241m=\u001b[39m _check_X(X)\n\u001b[0;32m    976\u001b[0m \u001b[38;5;66;03m# If ColumnTransformer is fit using a dataframe, and now a dataframe is\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;66;03m# passed to be transformed, we select columns by name instead. This\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# enables the user to pass X at transform time with extra columns which\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# were not present in fit time, and the order of the columns doesn't\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# matter.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\axell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"training_dataset.csv\")\n",
    "\n",
    "# Target dan fitur\n",
    "y = df[\"berlangganan_deposito\"]\n",
    "X = df.drop(columns=[\"berlangganan_deposito\", \"customer_number\"])\n",
    "\n",
    "# ===== PENANGANAN NILAI 999 =====\n",
    "X[\"pernah_dihubungi\"] = X[\"hari_sejak_kontak_sebelumnya\"] != 999\n",
    "X[\"hari_sejak_kontak_sebelumnya\"] = X[\"hari_sejak_kontak_sebelumnya\"].replace(999, np.nan)\n",
    "\n",
    "# Tambahkan flag untuk kategori 'unknown'\n",
    "X[\"is_gagal_bayar_unknown\"] = X[\"gagal_bayar_sebelumnya\"] == \"unknown\"\n",
    "X[\"is_pinjaman_rumah_unknown\"] = X[\"pinjaman_rumah\"] == \"unknown\"\n",
    "X[\"is_pinjaman_pribadi_unknown\"] = X[\"pinjaman_pribadi\"] == \"unknown\"\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ===== FITUR =====\n",
    "onehot_with_unknown = [\n",
    "    'gagal_bayar_sebelumnya', 'pinjaman_rumah', 'pinjaman_pribadi'\n",
    "]\n",
    "\n",
    "onehot_default = [\n",
    "    'pekerjaan', 'status_perkawinan', 'pendidikan', 'jenis_kontak',\n",
    "    'bulan_kontak_terakhir', 'hari_kontak_terakhir', 'hasil_kampanye_sebelumnya'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'usia', 'jumlah_kontak_kampanye_ini', 'hari_sejak_kontak_sebelumnya',\n",
    "    'jumlah_kontak_sebelumnya', 'tingkat_variasi_pekerjaan',\n",
    "    'indeks_harga_konsumen', 'indeks_kepercayaan_konsumen',\n",
    "    'suku_bunga_euribor_3bln', 'jumlah_pekerja', 'pernah_dihubungi',\n",
    "    'is_gagal_bayar_unknown', 'is_pinjaman_rumah_unknown', 'is_pinjaman_pribadi_unknown'\n",
    "]\n",
    "\n",
    "# ===== PREPROCESSING PIPELINE =====\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numerical_features),\n",
    "\n",
    "    ('cat_known', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ]), onehot_default),\n",
    "\n",
    "    ('cat_unknown_as_category', OneHotEncoder(\n",
    "        handle_unknown='ignore', sparse_output=False\n",
    "    ), onehot_with_unknown)\n",
    "])\n",
    "\n",
    "# ===== MODEL PIPELINES =====\n",
    "# Contoh untuk Random Forest\n",
    "pipeline_rf = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [10, None],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# Sama untuk Logistic Regression\n",
    "pipeline_lr = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', LogisticRegression(random_state=42, solver='liblinear'))\n",
    "])\n",
    "\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.1, 1.0, 10]\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "# XGBoost pipeline\n",
    "pipeline_xgb = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__subsample': [0.8, 1],\n",
    "    'classifier__colsample_bytree': [0.8, 1]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(pipeline_xgb, param_grid_xgb, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "\n",
    "# CatBoost pipeline\n",
    "pipeline_cat = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', CatBoostClassifier(random_state=42, verbose=0))\n",
    "])\n",
    "\n",
    "param_grid_cat = {\n",
    "    'classifier__iterations': [100, 200],\n",
    "    'classifier__depth': [4, 6],\n",
    "    'classifier__learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "grid_cat = GridSearchCV(pipeline_cat, param_grid_cat, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_cat.fit(X_train, y_train)\n",
    "best_cat = grid_cat.best_estimator_\n",
    "\n",
    "# LightGBM pipeline\n",
    "pipeline_lgb = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', LGBMClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_lgb = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [6, -1],\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__num_leaves': [31, 50]\n",
    "}\n",
    "\n",
    "grid_lgb = GridSearchCV(pipeline_lgb, param_grid_lgb, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_lgb.fit(X_train, y_train)\n",
    "best_lgb = grid_lgb.best_estimator_\n",
    "\n",
    "# ===== VOTING CLASSIFIER =====\n",
    "# Voting classifier dengan pipeline yang sudah termasuk preprocessor dan smote,\n",
    "# kita harus membuat pipeline voting tanpa smote lagi di sini,\n",
    "# jadi kita gunakan estimators yang hanya memuat model tanpa preprocessor dan smote.\n",
    "\n",
    "# Jadi, kita extract model dari pipeline untuk voting classifier,\n",
    "# dan buat pipeline voting yang menggabungkan preprocessing + voting.\n",
    "\n",
    "voting_estimators = [\n",
    "    ('rf', best_rf.named_steps['classifier']),\n",
    "    ('lr', best_lr.named_steps['classifier']),\n",
    "    ('xgb', best_xgb.named_steps['classifier']),\n",
    "    ('cat', best_cat.named_steps['classifier']),\n",
    "    ('lgb', best_lgb.named_steps['classifier'])\n",
    "]\n",
    "\n",
    "voting_clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting', VotingClassifier(\n",
    "        estimators=voting_estimators,\n",
    "        voting='soft',\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# ===== EVALUASI =====\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "y_proba = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "print(f\"\\nROC AUC Score: {auc_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
